{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: C\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "# Imports\n",
    "from pynattas.builder.netBuilder import GenericNetwork \n",
    "from pynattas.utils import layerCoder\n",
    "\n",
    "import configparser\n",
    "import pynattas as pnas\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "\n",
    "nas_check = config.getboolean(section='Mode', option='network_architecture_search')\n",
    "ht_check = config.getboolean(section='Mode', option='hyperparameter_tuning')\n",
    "\n",
    "\n",
    "task = config['Mode']['task']\n",
    "if task not in ['C','D']:\n",
    "    print(f\"Error: Selected Task {task} is not available. Check config_optimizer.ini for verification.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"Task: {task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Layers: 10\n",
      "Max Iterations: 4\n",
      "Population Size: 8\n",
      "Log Path: ./logs/GA_logs\n",
      "Mating Pool Cutoff: 0.8\n",
      "Mutation Probability: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Define NAS parameters and run GA\n",
    "max_layers = config.getint('NAS', 'max_layers')\n",
    "max_iterations = int(config['GA']['max_iterations'])\n",
    "population_size = int(config['GA']['population_size'])\n",
    "log_path = str(config['GA']['logs_dir_GA'])\n",
    "mating_pool_cutoff = float(config['GA']['mating_pool_cutoff'])\n",
    "mutation_probability = float(config['GA']['mutation_probability'])\n",
    "############################################\n",
    "print(f\"Max Layers: {max_layers}\")\n",
    "print(f\"Max Iterations: {max_iterations}\")\n",
    "print(f\"Population Size: {population_size}\")\n",
    "print(f\"Log Path: {log_path}\")\n",
    "print(f\"Mating Pool Cutoff: {mating_pool_cutoff}\")\n",
    "print(f\"Mutation Probability: {mutation_probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Population: 8\n",
      "Current Generation: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Lne5aln1|PM|Lne6agn1|PI|Lbo4k3s2p2aln1|PI|Ldo4agn1|PM|Leo2k5s1p2aln1|PI|Ldo2aln1|PI|HC||',\n",
       " 'Leo3k3s1p0agn1|PM|LPe3arn1|PM|Ldo3agn1|PM|LOaln1|PM|Leo3k5s2p0aln1|PM|HC||',\n",
       " 'Leo4k3s2p1agn1|PM|HC||',\n",
       " 'LPe4agn1|PM|Lco2k4s2p1aln1|PI|LOarn1|PI|Ldo3arn1|PI|HC||',\n",
       " 'Lbo2k3s2p0aln1|PM|LRr2agn1|PI|Leo3k5s2p2aln1|PM|Lme4arn1|PI|LOaln1|Pa|Lme3agn1|PM|Leo3k3s1p0aln1|PI|LOagn1|PI|Lbo4k3s2p1agn1|PI|HC||',\n",
       " 'Lco3k3s1p0agn1|PI|Lne6aln1|Pa|LRr4aln1|PI|Lne3arn1|PI|Leo4k5s1p2agn1|PI|LOarn1|PI|HC||',\n",
       " 'Lne6aln1|PI|LRr4aln1|Pa|Lme5aln1|Pa|LPe5agn1|PI|HC||',\n",
       " 'LOarn1|PM|LRr3arn1|Pa|Ldo3arn1|PM|LRr4aln1|PM|Ldo3aln1|Pa|LRr4aln1|PI|LOaln1|Pa|HC||']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define population\n",
    "from pynattas.builder.population import Population\n",
    "\n",
    "pop = Population(max_layers=max_layers, n_individuals=population_size)\n",
    "print(f\"Initial Population: {len(pop.population)}\")\n",
    "print(f\"Current Generation: {pop.iteration}\")\n",
    "\n",
    "[x.architecture for x in pop.population]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'layer_type': 'ConvBnAct',\n",
       "  'out_channels_coefficient': '3',\n",
       "  'kernel_size': '3',\n",
       "  'stride': '1',\n",
       "  'padding': '0',\n",
       "  'activation': 'GELU',\n",
       "  'num_blocks': '1'},\n",
       " {'layer_type': 'Identity'},\n",
       " {'layer_type': 'MBConvNoRes',\n",
       "  'expansion_factor': '6',\n",
       "  'activation': 'LeakyReLU',\n",
       "  'num_blocks': '1'},\n",
       " {'layer_type': 'AvgPool'},\n",
       " {'layer_type': 'ResNetBlock',\n",
       "  'reduction_factor': '4',\n",
       "  'activation': 'LeakyReLU',\n",
       "  'num_blocks': '1'},\n",
       " {'layer_type': 'Identity'},\n",
       " {'layer_type': 'MBConvNoRes',\n",
       "  'expansion_factor': '3',\n",
       "  'activation': 'ReLU',\n",
       "  'num_blocks': '1'},\n",
       " {'layer_type': 'Identity'},\n",
       " {'layer_type': 'ConvSE',\n",
       "  'out_channels_coefficient': '4',\n",
       "  'kernel_size': '5',\n",
       "  'stride': '1',\n",
       "  'padding': '2',\n",
       "  'activation': 'GELU',\n",
       "  'num_blocks': '1'},\n",
       " {'layer_type': 'Identity'},\n",
       " {'layer_type': 'CSPConvBlock', 'activation': 'ReLU', 'num_blocks': '1'},\n",
       " {'layer_type': 'Identity'},\n",
       " {'layer_type': 'ClassificationHead'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 5\n",
    "parsed_layers = layerCoder.parse_architecture_code(pop.population[idx].architecture)\n",
    "parsed_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 3\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "num_classes = 2\n",
    "\n",
    "Net = GenericNetwork(\n",
    "        parsed_layers, \n",
    "        input_channels,\n",
    "        input_height,\n",
    "        input_width,\n",
    "        num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenericNetwork(\n",
       "  (layers): ModuleList(\n",
       "    (0): ConvBnAct(\n",
       "      (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): GELU()\n",
       "    )\n",
       "    (1): Identity()\n",
       "    (2): MBConvNoRes(\n",
       "      (steps): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(\n",
       "            (LeakyReLU): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
       "        (2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): LeakyReLU(\n",
       "          (LeakyReLU): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (4): ConvBnAct(\n",
       "          (conv): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(\n",
       "            (LeakyReLU): LeakyReLU(negative_slope=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): AvgPool(\n",
       "      (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (4): ResNetBlock(\n",
       "      (main_path): ResNetBasicBlock(\n",
       "        (steps): Sequential(\n",
       "          (0): ConvBnAct(\n",
       "            (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(\n",
       "              (LeakyReLU): LeakyReLU(negative_slope=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBnAct(\n",
       "            (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(\n",
       "              (LeakyReLU): LeakyReLU(negative_slope=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): ConvBnAct(\n",
       "            (conv): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): LeakyReLU(\n",
       "              (LeakyReLU): LeakyReLU(negative_slope=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Identity()\n",
       "    (6): MBConvNoRes(\n",
       "      (steps): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
       "        (2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "        (4): ConvBnAct(\n",
       "          (conv): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Identity()\n",
       "    (8): ConvSE(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2d(96, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): GELU()\n",
       "      )\n",
       "      (1): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=24, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=24, out_features=384, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): Identity()\n",
       "    (10): CSPConvBlock(\n",
       "      (main_path): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (shortcut_path): Identity()\n",
       "      (final_transition): Sequential(\n",
       "        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (11): Identity()\n",
       "    (12): ClassificationHead(\n",
       "      (0): Linear(in_features=4731264, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(\n",
       "        (0): Dropout(p=0.4, inplace=False)\n",
       "      )\n",
       "      (3): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (jumpstart): ConvAct(\n",
       "    (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): LeakyReLU(\n",
       "      (LeakyReLU): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "segment = 'Lco3k4s2p1agn1'\n",
    "##########################\n",
    "params = segment[2:]  # Parameters portion of the segment\n",
    "\n",
    "# Extract alphanumeric pairs, keeping in mind cases like 'agn1'\n",
    "param_pairs = re.findall(r'[a-zA-Z]+[0-9]*', params)\n",
    "\n",
    "segment_info = {}\n",
    "for pair in param_pairs:\n",
    "    # Special case for 'agn1': manually split 'a:g' and 'n:1'\n",
    "    if pair.startswith('a'):\n",
    "        key_value_pairs = [(pair[0], pair[1]), (pair[2], pair[3])]\n",
    "    else:\n",
    "        key_value_pairs = [(pair[0], pair[1:])]\n",
    "\n",
    "    segment_info.update({key: value for key, value in key_value_pairs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pynattas.optimizers import ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nas_result = pnas.optimizers.ga.ga_optimizer(\n",
    "#     max_layers=max_layers,\n",
    "#     max_iter=max_iterations,\n",
    "#     n_individuals=population_size,\n",
    "#     mating_pool_cutoff=mating_pool_cutoff,\n",
    "#     mutation_probability=mutation_probability,\n",
    "#     logs_directory=log_path,\n",
    "#     task=task,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynatas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
